# üìä Python ‚Äì Text Analytics & Media Analysis 

## Description
- In this assignment, I applied Python and text analytics techniques to analyze media content across U.S. and international news sources. The project focused on data collection, natural language processing (NLP), and visualization using histograms to uncover patterns in word usage. Through hands-on implementation, I strengthened my ability to transform unstructured text data into meaningful insights while addressing real-world business and media analysis questions .

## üì∞ Question 1 ‚Äì Media Article Collection
Overview
- For this question, I selected a single news topic covered within the last three months and scraped 10 total articles‚Äî7 from U.S.-based media channels and 3 from international outlets. Each article included the title, author(s), publication date, and full text. Non-coding scraping tools were primarily used, with Yahoo permitted as one optional coding-based source.

Skills Developed ‚Äì

Data Collection: 
- Learned how to gather structured data from multiple media sources using non-coding tools.

Source Validation: 
- Identified reputable U.S. and international news outlets and verified article metadata.

Documentation & Explanation: 
- Clearly demonstrated and explained scraping methods in a video format as required .

üìà Question 2 ‚Äì Unigram Histograms (U.S. vs International Media)
Code Overview

Using Python, I processed article text to calculate and visualize the top 10 unigrams for both U.S.-based and international news sources. Histograms were created to compare word frequency distributions between the two groups.

Skills Developed ‚Äì

Text Preprocessing: Cleaned and tokenized article text for analysis.

Data Visualization: Created histograms to represent unigram frequency distributions.

Comparative Analysis: Interpreted similarities and differences between U.S. and international media coverage .

üîó Question 3 ‚Äì Bigram & Trigram Analysis
Code Overview

This section expanded the analysis to include bigrams and trigrams, visualized through histograms for both U.S. and international sources. Additionally, stemming and lemmatization techniques were compared to evaluate their impact on text patterns.

Skills Developed ‚Äì

N-gram Modeling: Generated bigrams and trigrams to capture contextual word relationships.

Advanced NLP Techniques: Applied stemming and lemmatization to compare linguistic normalization methods.

Critical Interpretation: Analyzed how phrase-level patterns differed across regions and preprocessing techniques .

üåç Question 4 ‚Äì Non-English NLP with NLTK (GenAI-Permitted)
Code Overview

For this GenAI-permitted question, I installed an NLTK language package for a non-English language and analyzed a foreign-language article scraped using non-coding methods. Histograms for unigrams, bigrams, and trigrams were generated and compared to English-language results from earlier questions.

Skills Developed ‚Äì

Multilingual NLP: Installed and used a non-English NLTK language package.

Cross-Language Comparison: Identified similarities and differences between English and non-English text patterns.

Engagement Analysis: Explored potential relationships between word usage patterns and user engagement metrics such as likes or comments .

üìß Question 5 ‚Äì Email Spam Detection Analysis
Code Overview

In this question, I analyzed 20 spam emails by extracting and processing both the subject lines and body text. Top unigrams, bigrams, and trigrams were calculated to identify common linguistic patterns associated with spam content.

Skills Developed ‚Äì

Text Classification Foundations: Identified linguistic features commonly associated with spam emails.

Feature Extraction: Compared word and phrase patterns between email titles and body text.

Practical Application: Evaluated how n-gram frequency supports spam detection logic .
